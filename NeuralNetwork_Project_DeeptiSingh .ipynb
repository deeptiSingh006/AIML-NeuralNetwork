{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1f49410",
   "metadata": {},
   "source": [
    "# DOMAIN: Electronics and Telecommunication\n",
    "## • CONTEXT: A communications equipment manufacturing company has a product which is responsible for emitting informative signals.\n",
    "## Company wants to build a machine learning model which can help the company to predict the equipment’s signal quality using various parameters.\n",
    "\n",
    "### • DATA DESCRIPTION: The data set contains information on various signal tests performed:\n",
    "1. Parameters: Various measurable signal parameters.\n",
    "2. Signal_Quality: Final signal strength or quality\n",
    "\n",
    "## • PROJECT OBJECTIVE: To build a classifier which can use the given parameters to determine the signal strength or quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09ba4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part A - Q1 A - Read the ‘Signals.csv’ as DatFrame and import required libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats \n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.layers import Dense, Activation, LeakyReLU,ReLU\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Read the data as a data frame\n",
    "nn_signal = pd.read_csv('NN Project Data - Signal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ba46ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_signal.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03da4279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part A - Q1 B - Check for missing values and print percentage for each attribute.\n",
    "nn_signal.isnull().mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12871198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: No missing values in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b64b228",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_signal.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b787ea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count for all parmeters have 1599 records hence proces no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe56b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part A - Q1 C - Check for presence of duplicate records in the dataset and impute with appropriate method.\n",
    "\n",
    "nn_signal_duplicate = nn_signal[nn_signal.duplicated()]\n",
    " \n",
    "print(\"List of Duplicate Rows:\")\n",
    "# Lis tof duplicate rows in dataframe\n",
    "nn_signal_duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b410172",
   "metadata": {},
   "outputs": [],
   "source": [
    "#240 row are duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7add2182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows\n",
    "nn_signal.drop_duplicates(keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ff664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf6e037",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part A - Q1 D - Visualise distribution of the target variable.\n",
    "sns.countplot(nn_signal['Signal_Strength']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1513089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part A - Q1 E - Share insights from the initial data analysis (at least 2).\n",
    "# There are 6 categories of signal to be predicted from label 3 to 8 \n",
    "# Class 5 and Class 6 has highest count\n",
    "# 240 duplicate rows were present in data that were removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fb2515",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part A - Q2 A - Split the data into X & Y.\n",
    "X = nn_signal.drop('Signal_Strength', axis=1)\n",
    "y = nn_signal.pop('Signal_Strength')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd00a491",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee4ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part A - Q2 B - Split the data into train & test with 70:30 proportion\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355de1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08562929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A - Q2 C - Print shape of all the 4 variables and verify if train and test data is in sync.\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82bfa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50ac1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185466e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All classes presentin test and train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6459536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part A - Q2 D - Normalise the train and test data with appropriate method.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8802b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part A - Q2 E - Transform Labels into format acceptable by Neural Network\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4413b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes=9)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372f1d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3261c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part A - Q3 A - Design a Neural Network to train a classifier.\n",
    "\n",
    "# splitting data for  train and validation of categorial \n",
    "Xc_train, Xc_val, yc_train, yc_val = train_test_split(X_train, y_train, test_size=.20, random_state=11)\n",
    "\n",
    "#Initialize Sequential model\n",
    "model = tensorflow.keras.models.Sequential()\n",
    "\n",
    "#Input\n",
    "model.add(tensorflow.keras.layers.Dense(128,kernel_initializer='normal', activation='sigmoid'))\n",
    "#HL 2\n",
    "model.add(tensorflow.keras.layers.Dense(64,kernel_initializer='normal', activation='sigmoid'))\n",
    "#HL 2\n",
    "model.add(tensorflow.keras.layers.Dense(32,kernel_initializer='normal', activation='sigmoid'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "#Output\n",
    "model.add(tensorflow.keras.layers.Dense(9, kernel_initializer='normal',activation='softmax'))\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer='sgd',loss='mean_absolute_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23a1bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part A - Q3 B - Train the classifier using previously designed Architecture\n",
    "EPOCH=300\n",
    "model_cal=model.fit(x=Xc_train, y=yc_train, batch_size=30, epochs= EPOCH, validation_data=(Xc_val, yc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f4ca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part A - Q3 C - Plot 2 separate visuals. \n",
    "#i. Training Loss and Validation Loss \n",
    "loss_train = model_cal.history['loss']\n",
    "loss_val = model_cal.history['val_loss']\n",
    "epochs = range(1,EPOCH+1)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af55043",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ii. Training Accuracy and Validation Accuracy\n",
    "Acc_train = model_cal.history['accuracy']\n",
    "Acc_val = model_cal.history['val_accuracy']\n",
    "epochs = range(1,EPOCH+1)\n",
    "plt.plot(epochs, Acc_train, 'g', label='Training accuracy')\n",
    "plt.plot(epochs, Acc_val, 'b', label='validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064aa4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part A - Q3 D - Design new architecture/update existing architecture \n",
    "#in attempt to improve the performance of the model.\n",
    "\n",
    "#Initialize Sequential model\n",
    "model = tensorflow.keras.models.Sequential()\n",
    "#Input\n",
    "model.add(tensorflow.keras.layers.Dense(128,kernel_initializer='normal', activation='relu'))\n",
    "#HL1\n",
    "model.add(tensorflow.keras.layers.Dense(64,kernel_initializer='normal', activation='relu'))\n",
    "#HL2\n",
    "model.add(tensorflow.keras.layers.Dense(32,kernel_initializer='normal', activation='relu'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "#HL3\n",
    "model.add(tensorflow.keras.layers.Dense(16,kernel_initializer='normal', activation='relu'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "#OUTPUT layer\n",
    "model.add(tensorflow.keras.layers.Dense(9, kernel_initializer='normal',activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db843f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(optimizer='adam',loss='mean_absolute_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952c7fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH=300\n",
    "model_cal=model.fit(x=Xc_train, y=yc_train, batch_size=32, epochs= EPOCH, validation_data=(Xc_val, yc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285681f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part A - Q3 E - Plot visuals as in Q3.C and share insights about difference observed in both the models.\n",
    "loss_train = model_cal.history['loss']\n",
    "loss_val = model_cal.history['val_loss']\n",
    "epochs = range(1,EPOCH+1)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "plt.title('Training & Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e35fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Acc_train = model_cal.history['accuracy']\n",
    "Acc_val = model_cal.history['val_accuracy']\n",
    "epochs = range(1,EPOCH+1)\n",
    "plt.plot(epochs, Acc_train, 'g', label='Training accuracy')\n",
    "plt.plot(epochs, Acc_val, 'b', label='Validation accuracy')\n",
    "plt.title('Training & Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1d23dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observations:\n",
    "# 2nd model is better using ADAM as the optimsier and RELU as activation function instead of SGD ( stocastic gradient descent)\n",
    "# Accuracy of the model increased from 42% to 62% when RELU was used as the activation function instead of sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc25e217",
   "metadata": {},
   "source": [
    "# DOMAIN: Autonomous Vehicles\n",
    "## • CONTEXT: A Recognising multi-digit numbers in photographs captured at street level is an important component of modern-day map making. A classic example of a corpus of such street-level photographs is Google’s Street View imagery composed of hundreds of millions of geo-located 360-degree panoramic images. The ability to automatically transcribe an address number from a geo-located patch of pixels and associate the transcribed number with a known street address helps pinpoint, with a high degree of accuracy, the location of the building it represents. More broadly, recognising numbers in photographs is a problem of interest to the optical character recognition community. While OCR on constrained domains like document processing is well studied, arbitrary multi-character text recognition in photographs is still highly challenging. This difficulty arises due to the wide variability in the visual appearance of text in the wild on account of a large range of fonts, colours, styles, orientations, and character arrangements. The recognition problem is further complicated by environmental factors such as lighting, shadows, specularity, and occlusions as well as by image acquisition factors such as resolution, motion, and focus blurs. In this project, we will use the dataset with images centred around a single digit (many of the images do contain some distractors at the sides). Although we are taking a sample of the data which is simpler, it is more complex than MNIST because of the distractors.\n",
    "\n",
    "## • DATA DESCRIPTION: The SVHN is a real-world image dataset for developing machine learning and object recognition algorithms with the minimal requirement on data formatting but comes from a significantly harder, unsolved, real-world problem (recognising digits and numbers in natural scene images). SVHN is obtained from house numbers in Google Street View images.\n",
    "\n",
    "## Where the labels for each of this image are the prominent number in that image i.e. 2,6,7 and 4 respectively. The dataset has been provided in the form of h5py files. You can read about this file format here: https://docs.h5py.org/en/stable/\n",
    "## Acknowledgement: Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng Reading Digits in Natural Images with Unsupervised Feature Learning NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011. PDF\n",
    "## http://ufldl.stanford.edu/housenumbers as the URL for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbdc696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import json\n",
    "import tensorflow as tf\n",
    "import keras as kr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc13ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B - Q1 A - Read the .h5 file and assign to a variable.\n",
    "datah5py=h5py.File('Autonomous_Vehicles_SVHN_single_grey1.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7102018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B - Q1 B - Print all the keys from the .h5 file.\n",
    "datah5py.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbabece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B - Q1 C - Split the data into X_train, X_test, Y_train, Y_test\n",
    "X_train=datah5py['X_train']\n",
    "X_test=datah5py['X_test']\n",
    "X_val=datah5py['X_val']\n",
    "y_train=datah5py['y_train']\n",
    "y_test=datah5py['y_test']\n",
    "y_val=datah5py['y_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a752fc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B - Q2 A - Print shape of all the 4 data split into x, y, train, test to verify if x & y is in sync.\n",
    "\n",
    "print(\"Training data   X_train :\", X_train.shape)\n",
    "print(\"Testing data    X_test  :\", X_test.shape)\n",
    "print(\"Validation data X_val   :\", X_val.shape)\n",
    "print(\"Training data   y_train :\", y_train.shape)\n",
    "print(\"Testing data    y_test  :\", y_test.shape)\n",
    "print(\"Validation data y_val :\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9c68e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classes are balanced in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa35841",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B - Q2 B - Visualise first 10 images in train data and print its corresponding labels.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 1))\n",
    "for img in range(10):\n",
    "    plt.subplot(1, 10, img+1)\n",
    "    plt.imshow(X_train[img].reshape(32,32),cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "print('Image Labes: %s' % (y_train[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155613f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B - Q2 C -Reshape all the images with appropriate shape update the data in same variable.\n",
    "X_val = np.asarray(X_val).reshape(60000,1024)\n",
    "X_train = np.asarray(X_train).reshape(42000,1024)\n",
    "X_test = np.asarray(X_test).reshape(18000,1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e0ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B - Q2 D - Normalise the images i.e. Normalise the pixel values.\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_val =X_val /255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a568fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B - Q2 E - Transform Labels into format acceptable by Neural Network\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "y_val = tensorflow.keras.utils.to_categorical(y_val, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacf9d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B - Q2 F - Print total Number of classes in the Dataset.\n",
    "print(\"Dataset shape:\")\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "num_classes = y_test.shape[1] \n",
    "print(\"Classes in dataset:\",num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914fc888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B - Q3 A - Design a Neural Network to train a classifier.\n",
    "model = Sequential()\n",
    "#Input layer and activation functions ReLU\n",
    "model.add(Dense(512, activation=\"relu\", kernel_initializer='he_uniform',input_shape = (1024, )))\n",
    "#HL 1\n",
    "model.add(Dense(128, activation=\"relu\", kernel_initializer='he_uniform'))\n",
    "#HL 2\n",
    "model.add(Dense(64, activation=\"relu\", kernel_initializer='he_uniform'))\n",
    "#HL 3\n",
    "model.add(Dense(32,  activation=\"relu\",  kernel_initializer='he_uniform'))\n",
    "# Output Layer\n",
    "model.add(Dense(10, kernel_initializer='he_normal', activation='softmax'))\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19188cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B - Q3 B - Train the classifier using previously designed Architecture (Use best suitable parameters).\n",
    "result = model.fit(X_train, y_train, validation_data=(X_val,y_val),batch_size = 300, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fe0b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B - Q3 C - Evaluate performance of the model with appropriate metrics.\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Loss:\", scores[0])\n",
    "print(\"Accuracy:\", scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36650f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B - Q3 D - Plot the training loss, validation loss vs number of epochs and training accuracy, \n",
    "#validation accuracy vs number of epochs plot and write your observations on the same.\n",
    "accuracy      = result.history['accuracy']\n",
    "val_accuracy  = result.history['val_accuracy']\n",
    "loss     = result.history['loss']\n",
    "val_loss = result.history['val_loss']\n",
    "\n",
    "epochs   = range(len(accuracy)) # Get number of epochs\n",
    "\n",
    "plt.plot  ( epochs, accuracy, label = 'Training accuracy')\n",
    "plt.plot  ( epochs, val_accuracy, label = 'Validation accuracy')\n",
    "plt.title ('Training & validation Accuracy')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.figure()\n",
    "\n",
    "plt.plot  ( epochs, loss, label = 'Training loss')\n",
    "plt.plot  ( epochs, val_loss, label = 'Validation loss')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.title ('Training & validation loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a9a397",
   "metadata": {},
   "source": [
    "Observation : The model has\n",
    "\n",
    "Training Accuracy : 89%\n",
    "Validation Accuracy : 87%\n",
    "Testing accuracy : 82%\n",
    "\n",
    "Which means that some overfitting is there but not much \n",
    "Adam optimiser produced good results. Relu activation also helped to get high accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
